{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chorltonm/fa-cup-upsets/blob/main/notebooks/source_apis/match_day_weather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JIdr0pAQuut"
      },
      "outputs": [],
      "source": [
        "# Import Libaries\n",
        "\n",
        "import requests\n",
        "import math\n",
        "import json\n",
        "import subprocess\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account\n",
        "from google.colab import drive\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change default ouput directory\n",
        "os.chdir('/content/drive/MyDrive/birkbeck_msc-project/output_files')"
      ],
      "metadata": {
        "id": "7eECUc2E_DWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "q_mOJcAMi4HB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBQ6M4kkQ4-B"
      },
      "outputs": [],
      "source": [
        "# Authentication credentials and keys\n",
        "\n",
        "# Visual Crossing API Authentication & Headers\n",
        "userdata.get('vc_api_key')\n",
        "api_key = userdata.get('vc_api_key')\n",
        "\n",
        "# Google Service Account\n",
        "\n",
        "# Load the JSON key from local Google Collab file\n",
        "key = json.load(open('/content/drive/MyDrive/service_account.json', 'r'))\n",
        "\n",
        "# Authenticate using the loaded key\n",
        "credentials = service_account.Credentials.from_service_account_info(key)\n",
        "\n",
        "# Set up the BigQuery client with the credentials to project\n",
        "client = bigquery.Client(credentials=credentials, project='birkbeck-msc-project-422917')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_date_location_query = f\"SELECT * FROM preparation_layer.view_fa_cup_round_3_match_date_location\"\n",
        "\n",
        "match_date_location_data = client.query(match_date_location_query)\n",
        "\n",
        "with open(f\"fa_cup_round_3_weather_data.json\", 'w') as match_weather_file:\n",
        "    for date_location in match_date_location_data:\n",
        "      match_id = date_location['match_id']\n",
        "      match_date = date_location['match_date']\n",
        "      latitude = date_location['match_latitude']\n",
        "      longitude = date_location['match_longitude']\n",
        "\n",
        "      # Get weather for the match date, latitude and longitude\n",
        "      weather_endpoint = f'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{latitude},{longitude}/{match_date}?key={api_key}'\n",
        "      weather_response = requests.get(weather_endpoint)\n",
        "      weather_data = weather_response.json()\n",
        "\n",
        "      #Filter out the 'days.stations' data\n",
        "      filtered_weather_data = {\n",
        "            'address': weather_data['address'],\n",
        "            'days': [{k: v for k, v in day.items() if k != 'stations'} for day in weather_data['days']]\n",
        "        }\n",
        "\n",
        "      # Create a dictionary with match_id and weather_data\n",
        "      data_to_write = {\n",
        "            'match_id': match_id,\n",
        "            'weather_data': filtered_weather_data\n",
        "        }\n",
        "\n",
        "      weather_data_json = json.dumps(data_to_write)\n",
        "\n",
        "      match_weather_file.write(weather_data_json + \"\\n\")\n",
        "\n",
        "      print(data_to_write)"
      ],
      "metadata": {
        "id": "IBF22wfOladJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wI_kTnmGdb6"
      },
      "outputs": [],
      "source": [
        "# Load weather file to BIQ QUERY extract_layer weather table\n",
        "\n",
        "# Set the dataset and table name\n",
        "dataset_name = 'extract_layer'\n",
        "table_name = 'api_visual_crossing_weather'\n",
        "table_ref = client.dataset(dataset_name).table(table_name)\n",
        "\n",
        "# Load the final data file into the BiqQuery table\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "  source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
        "  write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
        "  autodetect=True\n",
        ")\n",
        "\n",
        "with open(f\"fa_cup_round_3_weather_data.json\", 'rb') as lineups_file:\n",
        "              job = client.load_table_from_file(\n",
        "                    lineups_file, table_ref, job_config=job_config\n",
        "                )\n",
        "# Wait for the job to complete\n",
        "job.result()\n",
        "total_rows = job.output_rows\n",
        "print(f\"Big Query Rows {total_rows} processed into {dataset_name}.{table_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAqak_ypHjnz"
      },
      "outputs": [],
      "source": [
        "# Load weather data into BIQ QUERY load_layer weather table\n",
        "\n",
        "# Set the target load dataset and table names\n",
        "load_dataset_name = 'load_layer'\n",
        "load_table_name = 'all_api_visual_crossing_weather'\n",
        "table_ref = client.dataset(load_dataset_name).table(load_table_name)\n",
        "\n",
        "# Delete rows already inserted\n",
        "delete_query = f\"DELETE FROM `{load_dataset_name}.{load_table_name}` WHERE match_id IN (SELECT DISTINCT match_id FROM `{dataset_name}.{table_name}`)\"\n",
        "delete_job = client.query(delete_query)\n",
        "delete_result = delete_job.result()\n",
        "total_rows_deleted = delete_result.num_dml_affected_rows\n",
        "print(f\"Big Query target table {load_dataset_name}.{load_table_name} rows deleted: {total_rows_deleted}\")\n",
        "\n",
        "# Define the load job configuration\n",
        "job_config = bigquery.QueryJobConfig(\n",
        "    destination=table_ref,\n",
        "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,\n",
        "    schema_update_options=[\n",
        "        bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define the SQL query\n",
        "insert_query = f\"SELECT * FROM `{dataset_name}.{table_name}`\"\n",
        "\n",
        "# Run the load job and wait for the job to complete\n",
        "load_job = client.query(insert_query, job_config=job_config)\n",
        "\n",
        "\n",
        "try:\n",
        "  load_job_result = load_job.result()\n",
        "\n",
        "  total_rows = load_job_result.total_rows\n",
        "  loaded_rows = job.output_rows\n",
        "  print(f\"Big Query target table {load_dataset_name}.{load_table_name} rows inserted: {loaded_rows}\")\n",
        "  print(f\"Big Query target table {load_dataset_name}.{load_table_name} final row count: {total_rows} \")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    for error in job.errors:\n",
        "        print(f\"Error details: {error}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}