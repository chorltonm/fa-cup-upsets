{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqNNhokLWNtWlB6cfLEesa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chorltonm/fa-cup-upsets/blob/main/notebooks/models/logistic_regression_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "nEuX80dPfnRR"
      },
      "outputs": [],
      "source": [
        "# Import general python libaries\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import importlib\n",
        "\n",
        "# Google Cloud libraries\n",
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account\n",
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "\n",
        "# Scikit Learn libraries\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from matplotlib import pyplot\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Import user defined python functions\n",
        "import model_evaluation_functions\n",
        "importlib.reload(model_evaluation_functions)\n",
        "from model_evaluation_functions import create_model_results_df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change default ouput directory\n",
        "os.chdir('/content/drive/MyDrive/birkbeck_msc-project/python_files')\n",
        "\n"
      ],
      "metadata": {
        "id": "gl-LEV7vfuVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a32fbf1-bc52-4f7e-b987-2344ef969023"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authentication credentials and keys\n",
        "\n",
        "# Google Service Account\n",
        "\n",
        "# Load the JSON key from local Google Collab file\n",
        "key = json.load(open('/content/drive/MyDrive/service_account.json', 'r'))\n",
        "\n",
        "# Authenticate using the loaded key\n",
        "credentials = service_account.Credentials.from_service_account_info(key)\n",
        "\n",
        "# Set up the BigQuery client with the credentials to project\n",
        "client = bigquery.Client(credentials=credentials, project='birkbeck-msc-project-422917')"
      ],
      "metadata": {
        "id": "VeWnIKHFi_uN"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Data\n",
        "\n",
        "fa_cup_raw_features = \"\"\"\n",
        "    select * from preparation_layer.view_fa_cup_round_3_features\n",
        "\"\"\"\n",
        "\n",
        "fa_cup_raw_features_df = client.query(fa_cup_raw_features).to_dataframe()\n",
        "display(fa_cup_raw_features_df)\n",
        "\n",
        "\n",
        "all_results_df = pd.DataFrame(columns=['metric_id', 'metric'])\n",
        "display(all_results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zkSB4iD1gE8P",
        "outputId": "941c66fe-cc42-4119-a1ed-ca721afcc001"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [metric_id, metric]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f6600ef-c828-4a8c-b094-5205caf2371b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric_id</th>\n",
              "      <th>metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f6600ef-c828-4a8c-b094-5205caf2371b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f6600ef-c828-4a8c-b094-5205caf2371b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f6600ef-c828-4a8c-b094-5205caf2371b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "all_results_df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_home_advantage(X):\n",
        "\n",
        "    result = X.groupby(['home_team_league_level', 'away_team_league_level'])['home_win'].mean().reset_index()\n",
        "    result.columns = ['home_team_league_level', 'away_team_league_level', 'home_win_factor']\n",
        "    result['home_win_factor'] = result['home_win_factor'].round(3)\n",
        "\n",
        "    X = X.merge(result, on=['home_team_league_level', 'away_team_league_level'], how='left')\n",
        "    return X, 'home_win_factor'"
      ],
      "metadata": {
        "id": "JmaXYhQh2lyx"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard, no weights\n",
        "model_name = \"Standard LogisticRegression\"\n",
        "\n",
        "# Empty df for consolidating confusion report results\n",
        "all_results_df_slr = pd.DataFrame(columns=['metric_id', 'metric'])\n",
        "\n",
        "# Define the ranking systems\n",
        "ranking_systems = ['round_3_position', 'massey', 'colley', 'keener', 'trueskill', 'borda_count', 'local_kemeny_optimisation']\n",
        "\n",
        "# Get all columns except the target and ranking columns\n",
        "target_variable = 'target_variable'\n",
        "base_features = [col for col in fa_cup_raw_features_df.columns if col != target_variable and not any(f\"{team}_{ranking}\" in col for team in ['home_team', 'away_team'] for ranking in ranking_systems)]\n",
        "\n",
        "# Identify numeric and categorical columns\n",
        "numeric_features = fa_cup_raw_features_df[base_features].select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = fa_cup_raw_features_df[base_features].select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Define preprocessing steps\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "ranking_transformer = Pipeline(steps=[\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "# Define cross-validation strategy\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Loop through each ranking system\n",
        "for ranking in ranking_systems:\n",
        "    #print(f\"\\nRunning model for {ranking} ranking system\")\n",
        "    model_name_ranking = f\"{model_name} {ranking}\"\n",
        "    print(model_name_ranking)\n",
        "\n",
        "    # Prepare the feature set for the current ranking system\n",
        "    current_features = base_features + [f'home_team_{ranking}', f'away_team_{ranking}']\n",
        "    X = fa_cup_raw_features_df[current_features]\n",
        "    y = fa_cup_raw_features_df['target_variable']\n",
        "\n",
        "    # Update preprocessor with current features\n",
        "    #preprocessor = ColumnTransformer(\n",
        "     #   transformers=[\n",
        "      #      ('num', numeric_transformer, numeric_features),\n",
        "       #     ('cat', categorical_transformer, categorical_features),\n",
        "        #    ('rank', ranking_transformer, [f'home_team_{ranking}', f'away_team_{ranking}'])\n",
        "        #], verbose_feature_names_out=False)\n",
        "\n",
        "\n",
        "    # Initialize lists to store results for each fold of the model\n",
        "    fold_accuracies = []\n",
        "    confusion_matrices = []\n",
        "    classification_reports = []\n",
        "    all_y_true = []\n",
        "    all_y_pred = []\n",
        "\n",
        "    # Perform cross-validation\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(X, y), 1):\n",
        "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "        # Add home advantage factor\n",
        "        X_train, home_advantage_column = add_home_advantage(X_train)\n",
        "        X_val, _ = add_home_advantage(X_val)\n",
        "\n",
        "        # Update numeric_features to include the home advantage column\n",
        "        numeric_features_with_ha = [home_advantage_column] + numeric_features\n",
        "        #print(numeric_features_with_ha)\n",
        "\n",
        "        # Update preprocessor with current features including home advantage\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', numeric_transformer, numeric_features_with_ha),\n",
        "                ('cat', categorical_transformer, categorical_features),\n",
        "                ('rank', ranking_transformer, [f'home_team_{ranking}', f'away_team_{ranking}'])\n",
        "            ], verbose_feature_names_out=False)\n",
        "\n",
        "        # Fit preprocessor and transform data\n",
        "        X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "        X_val_preprocessed = preprocessor.transform(X_val)\n",
        "\n",
        "        # Create pipeline\n",
        "        model = Pipeline([\n",
        "          ('preprocessor', preprocessor),\n",
        "          ('classifier', LogisticRegression(max_iter=100))\n",
        "          ])\n",
        "\n",
        "        # Get feature names after preprocessing\n",
        "        feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed, columns=feature_names, index=X_train.index)\n",
        "        X_val_preprocessed_df = pd.DataFrame(X_val_preprocessed, columns=feature_names, index=X_val.index)\n",
        "\n",
        "        # Simple check for missing values\n",
        "        if X_train_preprocessed_df.isnull().values.any() or X_val_preprocessed_df.isnull().values.any():\n",
        "          raise ValueError(\"Missing values found in preprocessed data. Please review your preprocessing steps.\")\n",
        "\n",
        "        print(f\"\\nFold {fold}\")\n",
        "        print(\"Preprocessed Train data:\")\n",
        "        display(X_train_preprocessed_df)\n",
        "        #print(\"\\nPreprocessed Test data:\")\n",
        "        #display(pd.concat([X_val_preprocessed_df, y_val], axis=1))\n",
        "\n",
        "        # Fit and predict\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        fold_accuracies.append(accuracy)\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_val, y_pred)\n",
        "        confusion_matrices.append(cm)\n",
        "\n",
        "        # Generate classification report\n",
        "        cr = classification_report(y_val, y_pred, output_dict=True)\n",
        "        classification_reports.append(cr)\n",
        "\n",
        "        # Store true and predicted values for later analysis\n",
        "        all_y_true.extend(y_val)\n",
        "        all_y_pred.extend(y_pred)\n",
        "\n",
        "        print(f\"Fold {fold} Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "    # Calculate average accuracy\n",
        "    avg_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
        "    print(f\"Average Accuracy: {avg_accuracy:.3f}\")\n",
        "\n",
        "    # Create and display results using your existing function\n",
        "    results_df= create_model_results_df(all_y_true, all_y_pred, fold_accuracies, model_name_ranking)\n",
        "    results_df = results_df.reset_index()\n",
        "    results_df['metric_id'] = results_df.index + 1\n",
        "    results_df = results_df[['metric_id', 'metric', model_name_ranking]]\n",
        "\n",
        "    all_results_df_slr = all_results_df_slr.merge(results_df, on=['metric_id', 'metric'], how='outer')\n",
        "\n",
        "display(all_results_df_slr)\n"
      ],
      "metadata": {
        "id": "IswmUv6u73D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard, no weights\n",
        "model_name = \"Standard LogisticRegression with home advantage\"\n",
        "\n",
        "# Empty df for consolidating confusion report results\n",
        "all_results_df_slrh = pd.DataFrame(columns=['metric_id', 'metric'])\n",
        "\n",
        "# Define the ranking systems\n",
        "ranking_systems = ['round_3_position', 'massey', 'colley', 'keener', 'trueskill', 'borda_count', 'local_kemeny_optimisation']\n",
        "\n",
        "# Get all columns except the target and ranking columns\n",
        "target_variable = 'target_variable'\n",
        "base_features = [col for col in fa_cup_raw_features_df.columns if col != target_variable and not any(f\"{team}_{ranking}\" in col for team in ['home_team', 'away_team'] for ranking in ranking_systems)]\n",
        "\n",
        "# Identify numeric and categorical columns\n",
        "numeric_features = fa_cup_raw_features_df[base_features].select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = fa_cup_raw_features_df[base_features].select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Define preprocessing steps\n",
        "\n",
        "home_advantage_transformer = FunctionTransformer(home_advantage, validate=False)\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "ranking_transformer = Pipeline(steps=[\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "# Define cross-validation strategy\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Loop through each ranking system\n",
        "for ranking in ranking_systems:\n",
        "    #print(f\"\\nRunning model for {ranking} ranking system\")\n",
        "    model_name_ranking = f\"{model_name} {ranking}\"\n",
        "    print(model_name_ranking)\n",
        "\n",
        "    # Prepare the feature set for the current ranking system\n",
        "    current_features = base_features + [f'home_team_{ranking}', f'away_team_{ranking}']\n",
        "    X = fa_cup_raw_features_df[current_features]\n",
        "    y = fa_cup_raw_features_df['target_variable']\n",
        "\n",
        "    # Update preprocessor with current features\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('home_advantage', home_advantage_transformer, ['home_team_league_level', 'away_team_league_level', 'home_win']),\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features),\n",
        "            ('rank', ranking_transformer, [f'home_team_{ranking}', f'away_team_{ranking}'])\n",
        "        ], verbose_feature_names_out=False)\n",
        "\n",
        "\n",
        "    # Initialize lists to store results for each fold of the model\n",
        "    fold_accuracies = []\n",
        "    confusion_matrices = []\n",
        "    classification_reports = []\n",
        "    all_y_true = []\n",
        "    all_y_pred = []\n",
        "\n",
        "    # Perform cross-validation\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(X, y), 1):\n",
        "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "        # Fit preprocessor and transform data\n",
        "        X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "        X_val_preprocessed = preprocessor.transform(X_val)\n",
        "\n",
        "        # Create pipeline\n",
        "        model = Pipeline([\n",
        "          ('preprocessor', preprocessor),\n",
        "          ('classifier', LogisticRegression(max_iter=100))\n",
        "          ])\n",
        "\n",
        "        # Get feature names after preprocessing\n",
        "        feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed, columns=feature_names, index=X_train.index)\n",
        "        X_val_preprocessed_df = pd.DataFrame(X_val_preprocessed, columns=feature_names, index=X_val.index)\n",
        "\n",
        "        # Simple check for missing values\n",
        "        if X_train_preprocessed_df.isnull().values.any() or X_val_preprocessed_df.isnull().values.any():\n",
        "          raise ValueError(\"Missing values found in preprocessed data. Please review your preprocessing steps.\")\n",
        "\n",
        "        #print(f\"\\nFold {fold}\")\n",
        "        #print(\"Preprocessed Train data:\")\n",
        "        #display(pd.concat([X_train_preprocessed_df, y_train], axis=1))\n",
        "        #print(\"\\nPreprocessed Test data:\")\n",
        "        #display(pd.concat([X_val_preprocessed_df, y_val], axis=1))\n",
        "\n",
        "        # Fit and predict\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        fold_accuracies.append(accuracy)\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_val, y_pred)\n",
        "        confusion_matrices.append(cm)\n",
        "\n",
        "        # Generate classification report\n",
        "        cr = classification_report(y_val, y_pred, output_dict=True)\n",
        "        classification_reports.append(cr)\n",
        "\n",
        "        # Store true and predicted values for later analysis\n",
        "        all_y_true.extend(y_val)\n",
        "        all_y_pred.extend(y_pred)\n",
        "\n",
        "        print(f\"Fold {fold} Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "    # Calculate average accuracy\n",
        "    avg_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
        "    print(f\"Average Accuracy: {avg_accuracy:.3f}\")\n",
        "\n",
        "    # Create and display results using your existing function\n",
        "    results_df= create_model_results_df(all_y_true, all_y_pred, fold_accuracies, model_name_ranking)\n",
        "    results_df = results_df.reset_index()\n",
        "    results_df['metric_id'] = results_df.index + 1\n",
        "    results_df = results_df[['metric_id', 'metric', model_name_ranking]]\n",
        "\n",
        "    all_results_df_slrh = all_results_df_slr.merge(results_df, on=['metric_id', 'metric'], how='outer')\n",
        "\n",
        "display(all_results_df_slrh)\n"
      ],
      "metadata": {
        "id": "XTRySz6Jnh3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weighted Logistc Regression\n",
        "model_name = \"Weighted LogisticRegression\"\n",
        "\n",
        "# Function to calculate weights\n",
        "def calculate_weights(y):\n",
        "    class_counts = y.value_counts()\n",
        "    total_samples = len(y)\n",
        "    return {class_label: int(round((1 - (count / total_samples)) * 100))\n",
        "            for class_label, count in class_counts.items()}\n",
        "\n",
        "# Define the ranking systems\n",
        "ranking_systems = ['round_3_position', 'massey', 'colley', 'keener', 'trueskill', 'borda_count', 'local_kemeny_optimisation']\n",
        "\n",
        "# Get all columns except the target and ranking columns\n",
        "target_variable = 'target_variable'\n",
        "base_features = [col for col in fa_cup_raw_features_df.columns if col != target_variable and not any(f\"{team}_{ranking}\" in col for team in ['home_team', 'away_team'] for ranking in ranking_systems)]\n",
        "\n",
        "\n",
        "# Identify numeric and categorical columns\n",
        "numeric_features = fa_cup_raw_features_df[base_features].select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = fa_cup_raw_features_df[base_features].select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Define preprocessing steps\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "ranking_transformer = Pipeline(steps=[\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "# Define cross-validation strategy\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Loop through each ranking system\n",
        "for ranking in ranking_systems:\n",
        "    model_name_ranking = f\"{model_name} {ranking}\"\n",
        "    print(model_name_ranking)\n",
        "\n",
        "    # Prepare the feature set for the current ranking system\n",
        "    current_features = base_features + [f'home_team_{ranking}', f'away_team_{ranking}']\n",
        "    X = fa_cup_raw_features_df[current_features]\n",
        "    y = fa_cup_raw_features_df['target_variable']\n",
        "\n",
        "    # Update preprocessor with current features\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features),\n",
        "            ('rank', ranking_transformer, [f'home_team_{ranking}', f'away_team_{ranking}'])\n",
        "        ], verbose_feature_names_out=False)\n",
        "\n",
        "    # Initialize lists to store results for each fold of the model\n",
        "    fold_accuracies = []\n",
        "    confusion_matrices = []\n",
        "    classification_reports = []\n",
        "    all_y_true = []\n",
        "    all_y_pred = []\n",
        "\n",
        "    # Perform cross-validation\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(X, y), 1):\n",
        "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "        # Fit preprocessor and transform data\n",
        "        X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "        X_val_preprocessed = preprocessor.transform(X_val)\n",
        "\n",
        "        # Get feature names after preprocessing\n",
        "        feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed, columns=feature_names, index=X_train.index)\n",
        "        X_val_preprocessed_df = pd.DataFrame(X_val_preprocessed, columns=feature_names, index=X_val.index)\n",
        "\n",
        "        # Calculate weights using only training data\n",
        "        weights = calculate_weights(y_train)\n",
        "\n",
        "        # Create pipeline\n",
        "        model = Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', LogisticRegression(class_weight=weights,max_iter=1000))\n",
        "        ])\n",
        "\n",
        "\n",
        "        # Simple check for missing values\n",
        "        if X_train_preprocessed_df.isnull().values.any() or X_val_preprocessed_df.isnull().values.any():\n",
        "          raise ValueError(\"Missing values found in preprocessed data. Please review your preprocessing steps.\")\n",
        "\n",
        "        #print(f\"\\nFold {fold}\")\n",
        "        #print(\"Preprocessed Train data:\")\n",
        "        #display(pd.concat([X_train_preprocessed_df, y_train], axis=1))\n",
        "        #print(\"\\nPreprocessed Test data:\")\n",
        "        #display(pd.concat([X_val_preprocessed_df, y_val], axis=1))\n",
        "\n",
        "        # Fit and predict\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        fold_accuracies.append(accuracy)\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_val, y_pred)\n",
        "        confusion_matrices.append(cm)\n",
        "\n",
        "        # Generate classification report\n",
        "        cr = classification_report(y_val, y_pred, output_dict=True)\n",
        "        classification_reports.append(cr)\n",
        "\n",
        "        # Store true and predicted values for later analysis\n",
        "        all_y_true.extend(y_val)\n",
        "        all_y_pred.extend(y_pred)\n",
        "\n",
        "        print(f\"Fold {fold} Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "    # Calculate average accuracy\n",
        "    avg_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
        "    print(f\"Average Accuracy: {avg_accuracy:.3f}\")\n",
        "\n",
        "    # Create and display results using your existing function\n",
        "    results_df= create_model_results_df(all_y_true, all_y_pred, fold_accuracies, model_name_ranking)\n",
        "    results_df = results_df.reset_index()\n",
        "    results_df['metric_id'] = results_df.index + 1\n",
        "    results_df = results_df[['metric_id', 'metric', model_name_ranking]]\n",
        "\n",
        "    all_results_df = all_results_df.merge(results_df, on=['metric_id', 'metric'], how='outer')\n",
        "\n",
        "display(all_results_df)\n"
      ],
      "metadata": {
        "id": "iYG67NmczJa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MCP Neural Network\n",
        "model_name = \"MLP Classifier Neural Network\"\n",
        "random_state= 47\n",
        "\n",
        "# Define the ranking systems\n",
        "ranking_systems = ['round_3_position', 'massey', 'colley', 'keener', 'trueskill', 'borda_count', 'local_kemeny_optimisation']\n",
        "\n",
        "# Get all columns except the target and ranking columns\n",
        "target_variable = 'target_variable'\n",
        "base_features = [col for col in fa_cup_raw_features_df.columns if col != target_variable and not any(f\"{team}_{ranking}\" in col for team in ['home_team', 'away_team'] for ranking in ranking_systems)]\n",
        "\n",
        "\n",
        "# Identify numeric and categorical columns\n",
        "numeric_features = fa_cup_raw_features_df[base_features].select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = fa_cup_raw_features_df[base_features].select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Define preprocessing steps\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "ranking_transformer = Pipeline(steps=[\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "# Define cross-validation strategy\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "\n",
        "# Loop through each ranking system\n",
        "for ranking in ranking_systems:\n",
        "    #print(f\"\\nRunning model for {ranking} ranking system\")\n",
        "    model_name_ranking = f\"{model_name} {ranking}\"\n",
        "    print(model_name_ranking)\n",
        "\n",
        "    # Prepare the feature set for the current ranking system\n",
        "    current_features = base_features + [f'home_team_{ranking}', f'away_team_{ranking}']\n",
        "    X = fa_cup_raw_features_df[current_features]\n",
        "    y = fa_cup_raw_features_df['target_variable']\n",
        "\n",
        "    # Update preprocessor with current features\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features),\n",
        "            ('rank', ranking_transformer, [f'home_team_{ranking}', f'away_team_{ranking}'])\n",
        "        ], verbose_feature_names_out=False)\n",
        "\n",
        "\n",
        "    # Initialize lists to store results for each fold of the model\n",
        "    fold_accuracies = []\n",
        "    confusion_matrices = []\n",
        "    classification_reports = []\n",
        "    all_y_true = []\n",
        "    all_y_pred = []\n",
        "\n",
        "    # Perform cross-validation\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(X, y), 1):\n",
        "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "        # Fit preprocessor and transform data\n",
        "        X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "        X_val_preprocessed = preprocessor.transform(X_val)\n",
        "\n",
        "        # Create pipeline\n",
        "        model = Pipeline([\n",
        "          ('preprocessor', preprocessor),\n",
        "          ('classifier', MLPClassifier(hidden_layer_sizes=(10), max_iter=10000, random_state=random_state))\n",
        "          ])\n",
        "\n",
        "        # Get feature names after preprocessing\n",
        "        feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        X_train_preprocessed_df = pd.DataFrame(X_train_preprocessed, columns=feature_names, index=X_train.index)\n",
        "        X_val_preprocessed_df = pd.DataFrame(X_val_preprocessed, columns=feature_names, index=X_val.index)\n",
        "\n",
        "        # Simple check for missing values\n",
        "        if X_train_preprocessed_df.isnull().values.any() or X_val_preprocessed_df.isnull().values.any():\n",
        "          raise ValueError(\"Missing values found in preprocessed data. Please review your preprocessing steps.\")\n",
        "\n",
        "        #print(f\"\\nFold {fold}\")\n",
        "        #print(\"Preprocessed Train data:\")\n",
        "        #display(pd.concat([X_train_preprocessed_df, y_train], axis=1))\n",
        "        #print(\"\\nPreprocessed Test data:\")\n",
        "        #display(pd.concat([X_val_preprocessed_df, y_val], axis=1))\n",
        "\n",
        "        # Fit and predict\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_val)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        fold_accuracies.append(accuracy)\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_val, y_pred)\n",
        "        confusion_matrices.append(cm)\n",
        "\n",
        "        # Generate classification report\n",
        "        cr = classification_report(y_val, y_pred, output_dict=True)\n",
        "        classification_reports.append(cr)\n",
        "\n",
        "        # Store true and predicted values for later analysis\n",
        "        all_y_true.extend(y_val)\n",
        "        all_y_pred.extend(y_pred)\n",
        "\n",
        "        print(f\"Fold {fold} Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "    # Calculate average accuracy\n",
        "    avg_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
        "    print(f\"Average Accuracy: {avg_accuracy:.3f}\")\n",
        "\n",
        "    # Create and display results using your existing function\n",
        "    results_df= create_model_results_df(all_y_true, all_y_pred, fold_accuracies, model_name_ranking)\n",
        "    results_df = results_df.reset_index()\n",
        "    results_df['metric_id'] = results_df.index + 1\n",
        "    results_df = results_df[['metric_id', 'metric', model_name_ranking]]\n",
        "\n",
        "    all_results_df = all_results_df.merge(results_df, on=['metric_id', 'metric'], how='outer')\n",
        "\n",
        "display(all_results_df)\n"
      ],
      "metadata": {
        "id": "pNLMkrvjwhoR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}